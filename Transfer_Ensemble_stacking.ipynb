{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de8e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "#from models import *\n",
    "#from utils import progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1859ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true',\n",
    "                    help='resume from checkpoint')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f41f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 25#300\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e341f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ColorJitter(0.1,0.1,0.1,0.1),\n",
    "    #전이학습\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224, padding=0),\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "    #과적합 방지 효과가 있다고 함\n",
    "    transforms.RandomRotation(3), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),#전이학습\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform_train)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=32,\n",
    "    #batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=32, \n",
    "    #batch_size=32, \n",
    "    shuffle=False, \n",
    "    num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d62f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "\n",
    "# net = ResNet50()\n",
    "# 전이학습\n",
    "#net = torchvision.models.resnet50(pretrained=True)\n",
    "net = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "#num_fltrs = net.fc.in_features\n",
    "\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd3b953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ConvBNActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6dd9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406e47aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNewNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNewNet, self).__init__()\n",
    "        self.resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.linear1 = nn.Linear(512*4, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        self.linear2 = nn.Linear(512, 10)\n",
    "\n",
    "    # Forward Pass 정의 부분\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        #x = self.linear1(x)\n",
    "        x = F.gelu(self.drop1(self.bn1(self.linear1(x))))\n",
    "    \n",
    "        return F.softmax(self.linear2(x), dim=1)\n",
    "    \n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.mobilenet_v2 = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(512*4+1280)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*4+1280, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.resnet50(x)     \n",
    "        out2 = self.mobilenet_v2(x)\n",
    "\n",
    "\n",
    "        out = torch.cat((out1 + out2),1)# + out3\n",
    "        \n",
    "        #\n",
    "\n",
    "        x = F.gelu(sefl.bn1(self.fc1(out)))\n",
    "        x = sefl.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21724777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model = MyNewNet()\n",
    "my_model = MyEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3fb1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyEnsemble(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mobilenet_v2): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ConvBNActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(3328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=3328, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6a2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_model.parameters():\n",
    "  param.requires_grad = True\n",
    "#for param in my_model.linear1.parameters():\n",
    "#  param.requires_grad = True\n",
    "#for param in my_model.linear2.parameters():\n",
    "#  param.requires_grad = True\n",
    "for param in my_model.fc1.parameters():\n",
    "  param.requires_grad = True\n",
    "for param in my_model.fc2.parameters():\n",
    "  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bbabb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  ---------\n",
      "adabelief-pytorch=0.0.5  1e-08  False              False\n",
      ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
      "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
      "----------------------------------------------------------  ----------------------------------------------\n",
      "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
      "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from adabelief_pytorch import AdaBelief\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "optimizer=AdaBelief(net.parameters(), lr=0.0001, eps =1e-16, betas=(0.9, 0.999),\n",
    "                    weight_decay = 5e-4, weight_decouple=False, rectify=False,\n",
    "                    fixed_decay=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff2bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoch_num, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a4b43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'.format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "    print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'.format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "    return (100. * correct / total)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'.format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        #  print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        #torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca0b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "lerningrate_temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Epoch: 0 | Batch_idx: 0 |  Loss: (9.8079) | Acc: (0.00%) (0/32)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (3.7781) | Acc: (35.60%) (581/1632)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (2.6060) | Acc: (48.24%) (1559/3232)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (2.0962) | Acc: (54.59%) (2638/4832)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (1.7822) | Acc: (59.45%) (3824/6432)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (1.5833) | Acc: (62.57%) (5026/8032)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (1.4391) | Acc: (64.88%) (6249/9632)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (1.3292) | Acc: (66.97%) (7522/11232)\n",
      "Epoch: 0 | Batch_idx: 400 |  Loss: (1.2381) | Acc: (68.71%) (8817/12832)\n",
      "Epoch: 0 | Batch_idx: 450 |  Loss: (1.1697) | Acc: (70.01%) (10104/14432)\n",
      "Epoch: 0 | Batch_idx: 500 |  Loss: (1.1109) | Acc: (71.11%) (11400/16032)\n",
      "Epoch: 0 | Batch_idx: 550 |  Loss: (1.0583) | Acc: (72.06%) (12705/17632)\n",
      "Epoch: 0 | Batch_idx: 600 |  Loss: (1.0105) | Acc: (73.03%) (14045/19232)\n",
      "Epoch: 0 | Batch_idx: 650 |  Loss: (0.9701) | Acc: (73.85%) (15384/20832)\n",
      "Epoch: 0 | Batch_idx: 700 |  Loss: (0.9387) | Acc: (74.50%) (16712/22432)\n",
      "Epoch: 0 | Batch_idx: 750 |  Loss: (0.9095) | Acc: (75.10%) (18047/24032)\n",
      "Epoch: 0 | Batch_idx: 800 |  Loss: (0.8814) | Acc: (75.76%) (19418/25632)\n",
      "Epoch: 0 | Batch_idx: 850 |  Loss: (0.8549) | Acc: (76.34%) (20789/27232)\n",
      "Epoch: 0 | Batch_idx: 900 |  Loss: (0.8321) | Acc: (76.83%) (22151/28832)\n",
      "Epoch: 0 | Batch_idx: 950 |  Loss: (0.8123) | Acc: (77.22%) (23501/30432)\n",
      "Epoch: 0 | Batch_idx: 1000 |  Loss: (0.7928) | Acc: (77.68%) (24884/32032)\n",
      "Epoch: 0 | Batch_idx: 1050 |  Loss: (0.7763) | Acc: (78.08%) (26259/33632)\n",
      "Epoch: 0 | Batch_idx: 1100 |  Loss: (0.7605) | Acc: (78.39%) (27620/35232)\n",
      "Epoch: 0 | Batch_idx: 1150 |  Loss: (0.7463) | Acc: (78.69%) (28983/36832)\n",
      "Epoch: 0 | Batch_idx: 1200 |  Loss: (0.7318) | Acc: (79.04%) (30378/38432)\n",
      "Epoch: 0 | Batch_idx: 1250 |  Loss: (0.7180) | Acc: (79.36%) (31770/40032)\n",
      "Epoch: 0 | Batch_idx: 1300 |  Loss: (0.7071) | Acc: (79.63%) (33153/41632)\n",
      "Epoch: 0 | Batch_idx: 1350 |  Loss: (0.6942) | Acc: (79.94%) (34561/43232)\n",
      "Epoch: 0 | Batch_idx: 1400 |  Loss: (0.6842) | Acc: (80.15%) (35933/44832)\n",
      "Epoch: 0 | Batch_idx: 1450 |  Loss: (0.6737) | Acc: (80.39%) (37326/46432)\n",
      "Epoch: 0 | Batch_idx: 1500 |  Loss: (0.6650) | Acc: (80.61%) (38718/48032)\n",
      "Epoch: 0 | Batch_idx: 1550 |  Loss: (0.6570) | Acc: (80.78%) (40095/49632)\n",
      "Epoch: 0 | Batch_idx: 1562 |  Loss: (0.6551) | Acc: (80.83%) (40416/50000)\n",
      "# TEST : Loss: (0.2635) | Acc: (91.24%) (9124/10000)\n",
      "9.96057350657239e-05\n",
      "\n",
      "Epoch: 1\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (0.2508) | Acc: (96.88%) (31/32)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (0.2916) | Acc: (90.38%) (1475/1632)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (0.3073) | Acc: (89.82%) (2903/3232)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (0.3116) | Acc: (89.61%) (4330/4832)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (0.3137) | Acc: (89.44%) (5753/6432)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (0.3229) | Acc: (89.39%) (7180/8032)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (0.3200) | Acc: (89.36%) (8607/9632)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (0.3206) | Acc: (89.36%) (10037/11232)\n",
      "Epoch: 1 | Batch_idx: 400 |  Loss: (0.3238) | Acc: (89.21%) (11447/12832)\n",
      "Epoch: 1 | Batch_idx: 450 |  Loss: (0.3246) | Acc: (89.21%) (12875/14432)\n",
      "Epoch: 1 | Batch_idx: 500 |  Loss: (0.3253) | Acc: (89.19%) (14299/16032)\n",
      "Epoch: 1 | Batch_idx: 550 |  Loss: (0.3275) | Acc: (89.16%) (15721/17632)\n",
      "Epoch: 1 | Batch_idx: 600 |  Loss: (0.3271) | Acc: (89.17%) (17150/19232)\n",
      "Epoch: 1 | Batch_idx: 650 |  Loss: (0.3241) | Acc: (89.19%) (18581/20832)\n",
      "Epoch: 1 | Batch_idx: 700 |  Loss: (0.3230) | Acc: (89.26%) (20023/22432)\n",
      "Epoch: 1 | Batch_idx: 750 |  Loss: (0.3206) | Acc: (89.34%) (21470/24032)\n",
      "Epoch: 1 | Batch_idx: 800 |  Loss: (0.3202) | Acc: (89.31%) (22893/25632)\n",
      "Epoch: 1 | Batch_idx: 850 |  Loss: (0.3215) | Acc: (89.27%) (24309/27232)\n",
      "Epoch: 1 | Batch_idx: 900 |  Loss: (0.3222) | Acc: (89.23%) (25726/28832)\n",
      "Epoch: 1 | Batch_idx: 950 |  Loss: (0.3210) | Acc: (89.29%) (27172/30432)\n",
      "Epoch: 1 | Batch_idx: 1000 |  Loss: (0.3206) | Acc: (89.28%) (28598/32032)\n",
      "Epoch: 1 | Batch_idx: 1050 |  Loss: (0.3196) | Acc: (89.32%) (30039/33632)\n",
      "Epoch: 1 | Batch_idx: 1100 |  Loss: (0.3188) | Acc: (89.35%) (31480/35232)\n",
      "Epoch: 1 | Batch_idx: 1150 |  Loss: (0.3177) | Acc: (89.38%) (32921/36832)\n",
      "Epoch: 1 | Batch_idx: 1200 |  Loss: (0.3168) | Acc: (89.39%) (34356/38432)\n",
      "Epoch: 1 | Batch_idx: 1250 |  Loss: (0.3165) | Acc: (89.43%) (35800/40032)\n",
      "Epoch: 1 | Batch_idx: 1300 |  Loss: (0.3155) | Acc: (89.44%) (37235/41632)\n",
      "Epoch: 1 | Batch_idx: 1350 |  Loss: (0.3136) | Acc: (89.48%) (38684/43232)\n",
      "Epoch: 1 | Batch_idx: 1400 |  Loss: (0.3133) | Acc: (89.51%) (40128/44832)\n",
      "Epoch: 1 | Batch_idx: 1450 |  Loss: (0.3122) | Acc: (89.54%) (41577/46432)\n",
      "Epoch: 1 | Batch_idx: 1500 |  Loss: (0.3120) | Acc: (89.54%) (43009/48032)\n",
      "Epoch: 1 | Batch_idx: 1550 |  Loss: (0.3116) | Acc: (89.56%) (44452/49632)\n",
      "Epoch: 1 | Batch_idx: 1562 |  Loss: (0.3115) | Acc: (89.56%) (44780/50000)\n",
      "# TEST : Loss: (0.2340) | Acc: (92.31%) (9231/10000)\n",
      "9.842915805643155e-05\n",
      "\n",
      "Epoch: 2\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (0.4037) | Acc: (93.75%) (30/32)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (0.2789) | Acc: (90.75%) (1481/1632)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (0.2522) | Acc: (91.86%) (2969/3232)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (0.2415) | Acc: (91.99%) (4445/4832)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (0.2419) | Acc: (92.01%) (5918/6432)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (0.2395) | Acc: (92.02%) (7391/8032)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (0.2413) | Acc: (91.93%) (8855/9632)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (0.2405) | Acc: (91.93%) (10326/11232)\n",
      "Epoch: 2 | Batch_idx: 400 |  Loss: (0.2429) | Acc: (91.82%) (11782/12832)\n",
      "Epoch: 2 | Batch_idx: 450 |  Loss: (0.2442) | Acc: (91.75%) (13242/14432)\n",
      "Epoch: 2 | Batch_idx: 500 |  Loss: (0.2425) | Acc: (91.82%) (14721/16032)\n",
      "Epoch: 2 | Batch_idx: 550 |  Loss: (0.2418) | Acc: (91.82%) (16189/17632)\n",
      "Epoch: 2 | Batch_idx: 600 |  Loss: (0.2399) | Acc: (91.87%) (17668/19232)\n",
      "Epoch: 2 | Batch_idx: 650 |  Loss: (0.2376) | Acc: (91.96%) (19157/20832)\n",
      "Epoch: 2 | Batch_idx: 700 |  Loss: (0.2377) | Acc: (91.98%) (20633/22432)\n",
      "Epoch: 2 | Batch_idx: 750 |  Loss: (0.2373) | Acc: (92.02%) (22114/24032)\n",
      "Epoch: 2 | Batch_idx: 800 |  Loss: (0.2365) | Acc: (92.03%) (23590/25632)\n",
      "Epoch: 2 | Batch_idx: 850 |  Loss: (0.2392) | Acc: (91.98%) (25048/27232)\n",
      "Epoch: 2 | Batch_idx: 900 |  Loss: (0.2376) | Acc: (92.04%) (26536/28832)\n",
      "Epoch: 2 | Batch_idx: 950 |  Loss: (0.2361) | Acc: (92.09%) (28025/30432)\n",
      "Epoch: 2 | Batch_idx: 1000 |  Loss: (0.2356) | Acc: (92.13%) (29512/32032)\n",
      "Epoch: 2 | Batch_idx: 1050 |  Loss: (0.2370) | Acc: (92.08%) (30969/33632)\n",
      "Epoch: 2 | Batch_idx: 1100 |  Loss: (0.2370) | Acc: (92.08%) (32443/35232)\n",
      "Epoch: 2 | Batch_idx: 1150 |  Loss: (0.2376) | Acc: (92.06%) (33909/36832)\n",
      "Epoch: 2 | Batch_idx: 1200 |  Loss: (0.2378) | Acc: (92.04%) (35373/38432)\n",
      "Epoch: 2 | Batch_idx: 1250 |  Loss: (0.2387) | Acc: (92.01%) (36834/40032)\n",
      "Epoch: 2 | Batch_idx: 1300 |  Loss: (0.2383) | Acc: (92.02%) (38310/41632)\n",
      "Epoch: 2 | Batch_idx: 1350 |  Loss: (0.2378) | Acc: (92.04%) (39790/43232)\n",
      "Epoch: 2 | Batch_idx: 1400 |  Loss: (0.2379) | Acc: (92.04%) (41265/44832)\n",
      "Epoch: 2 | Batch_idx: 1450 |  Loss: (0.2366) | Acc: (92.07%) (42750/46432)\n",
      "Epoch: 2 | Batch_idx: 1500 |  Loss: (0.2355) | Acc: (92.09%) (44231/48032)\n",
      "Epoch: 2 | Batch_idx: 1550 |  Loss: (0.2362) | Acc: (92.07%) (45694/49632)\n",
      "Epoch: 2 | Batch_idx: 1562 |  Loss: (0.2366) | Acc: (92.05%) (46026/50000)\n",
      "# TEST : Loss: (0.2403) | Acc: (92.49%) (9249/10000)\n",
      "9.648882429441257e-05\n",
      "\n",
      "Epoch: 3\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (0.2834) | Acc: (90.62%) (29/32)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (0.1838) | Acc: (93.87%) (1532/1632)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (0.1889) | Acc: (93.53%) (3023/3232)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (0.1888) | Acc: (93.67%) (4526/4832)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (0.1912) | Acc: (93.70%) (6027/6432)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (0.1890) | Acc: (93.79%) (7533/8032)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (0.1927) | Acc: (93.57%) (9013/9632)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (0.1926) | Acc: (93.56%) (10509/11232)\n",
      "Epoch: 3 | Batch_idx: 400 |  Loss: (0.1940) | Acc: (93.48%) (11995/12832)\n",
      "Epoch: 3 | Batch_idx: 450 |  Loss: (0.1960) | Acc: (93.33%) (13470/14432)\n",
      "Epoch: 3 | Batch_idx: 500 |  Loss: (0.1986) | Acc: (93.30%) (14958/16032)\n",
      "Epoch: 3 | Batch_idx: 550 |  Loss: (0.2012) | Acc: (93.16%) (16426/17632)\n",
      "Epoch: 3 | Batch_idx: 600 |  Loss: (0.2020) | Acc: (93.15%) (17915/19232)\n",
      "Epoch: 3 | Batch_idx: 650 |  Loss: (0.2005) | Acc: (93.17%) (19410/20832)\n",
      "Epoch: 3 | Batch_idx: 700 |  Loss: (0.2019) | Acc: (93.11%) (20886/22432)\n",
      "Epoch: 3 | Batch_idx: 750 |  Loss: (0.2003) | Acc: (93.14%) (22384/24032)\n",
      "Epoch: 3 | Batch_idx: 800 |  Loss: (0.1998) | Acc: (93.20%) (23889/25632)\n",
      "Epoch: 3 | Batch_idx: 850 |  Loss: (0.2003) | Acc: (93.16%) (25370/27232)\n",
      "Epoch: 3 | Batch_idx: 900 |  Loss: (0.1999) | Acc: (93.16%) (26860/28832)\n",
      "Epoch: 3 | Batch_idx: 950 |  Loss: (0.2007) | Acc: (93.17%) (28353/30432)\n",
      "Epoch: 3 | Batch_idx: 1000 |  Loss: (0.2006) | Acc: (93.12%) (29827/32032)\n",
      "Epoch: 3 | Batch_idx: 1050 |  Loss: (0.1997) | Acc: (93.17%) (31334/33632)\n",
      "Epoch: 3 | Batch_idx: 1100 |  Loss: (0.1995) | Acc: (93.16%) (32822/35232)\n",
      "Epoch: 3 | Batch_idx: 1150 |  Loss: (0.1994) | Acc: (93.19%) (34323/36832)\n",
      "Epoch: 3 | Batch_idx: 1200 |  Loss: (0.1998) | Acc: (93.19%) (35815/38432)\n",
      "Epoch: 3 | Batch_idx: 1250 |  Loss: (0.1992) | Acc: (93.22%) (37317/40032)\n",
      "Epoch: 3 | Batch_idx: 1300 |  Loss: (0.1987) | Acc: (93.20%) (38803/41632)\n",
      "Epoch: 3 | Batch_idx: 1350 |  Loss: (0.2006) | Acc: (93.18%) (40282/43232)\n",
      "Epoch: 3 | Batch_idx: 1400 |  Loss: (0.2006) | Acc: (93.18%) (41774/44832)\n",
      "Epoch: 3 | Batch_idx: 1450 |  Loss: (0.1995) | Acc: (93.22%) (43286/46432)\n",
      "Epoch: 3 | Batch_idx: 1500 |  Loss: (0.1992) | Acc: (93.24%) (44785/48032)\n",
      "Epoch: 3 | Batch_idx: 1550 |  Loss: (0.1985) | Acc: (93.26%) (46287/49632)\n",
      "Epoch: 3 | Batch_idx: 1562 |  Loss: (0.1985) | Acc: (93.27%) (46633/50000)\n",
      "# TEST : Loss: (0.1922) | Acc: (93.83%) (9383/10000)\n",
      "9.381533400219318e-05\n",
      "\n",
      "Epoch: 4\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.0991) | Acc: (96.88%) (31/32)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (0.1799) | Acc: (93.93%) (1533/1632)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (0.1799) | Acc: (93.81%) (3032/3232)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (0.1655) | Acc: (94.43%) (4563/4832)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (0.1641) | Acc: (94.47%) (6076/6432)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (0.1642) | Acc: (94.40%) (7582/8032)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(start_epoch, start_epoch+epoch_num): \n",
    "        train_error.append(train(epoch))    \n",
    "        test_error.append(test(epoch))          \n",
    "        scheduler.step()\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        lerningrate_temp.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        #print(train_error)\n",
    "        #print(test_error)\n",
    "    \n",
    "    plt.plot(train_error,label='train_acc')\n",
    "    plt.plot(test_error,label='test_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(lerningrate_temp,label='lr')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
